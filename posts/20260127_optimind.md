+++
title = "OptiMind, un LLM de Microsoft para modelado de problemas de optimización"
hascode = true
date = Date(2026, 1, 27)
rss = "Una primera impresión, sin probarlo todavía de OptiMind, un LLM de Microsoft para modelado de problemas de optimización"

tags = ["optimizacion", "llm", "investigación operativa"]
+++

# OptiMind, un LLM de Microsoft para modelado de problemas de optimización

Microsoft lanzó [Optimind](https://www.microsoft.com/en-us/research/blog/optimind-a-small-language-model-with-optimization-expertise/), un pequaño modelo de lenguaje focalizado en modelos de optimización. Si bien no lo probé todavía, la idea luce tentadora: convertir lenguaje natural en modelos de optimización. Esto, seguramente, va a facilitar un montón la difusión de herramientas de [Investigación Operativa](https://es.wikipedia.org/wiki/Investigaci%C3%B3n_de_operaciones). 

Las pruebas publicadas son muy interesantes, aunque por lo que ví, usaron problemas del tipo de libro de texto, los cuales no tienen mucha ambigüedad. Creo que, en el corto plazo, el uso será por programadores para modelos chicos, y para expertos en optimización en el caso de lenguajes mas complejos, que detallen en profundidad las particularidades del problema actual (de hecho, el sistema está diseñado así: luego de una clasificación inicial del problema, se le solicita mas información al usuario a fin de afinar el modelo). 

Lo único que me hace ruido es que, aparentemente, genera código (Python en el ejemplo) en vez de un modelo. Tendría lógica si diseñara alguna heurística, pero me parece que es una limitante importante. En el ejemplo, _Optimind_ toma la formulación y genera un código _Python_ para construir un modelo de [_programación lineal_](https://es.wikipedia.org/wiki/Programaci%C3%B3n_lineal) llamando a la biblioteca [_gurobipy_](https://www.gurobi.com/faqs/gurobipy/), con código muy tuneado para este solver. Entiendo que pude ser así por como fue entrenado, por los datos disponibles (ChatGPT también intenta generarte código por default), pero esto limita el uso y la flexibilidad un montón: sería preferible que la salida fuera el modelo en si, en formato _LP_ o _MPS_ y la codificación posterior, en otra etapa.

Aquí el link al artículo técnico: [https://www.microsoft.com/en-us/research/publication/optimind-teaching-llms-to-think-like-optimization-experts/](https://www.microsoft.com/en-us/research/publication/optimind-teaching-llms-to-think-like-optimization-experts/). Y aquí el link del repo: [https://github.com/microsoft/OptiGuide](https://github.com/microsoft/OptiGuide) 

