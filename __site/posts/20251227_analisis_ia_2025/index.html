<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  
  <link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="/css/poole_hyde.css">
<!-- style adjustments -->
<style>
  html {font-size: 17px;}
  .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;}
  @media (min-width: 940px) {
    .franklin-content {width: 100%; margin-left: auto; margin-right: auto;}
  }
  @media (max-width: 768px) {
    .franklin-content {padding-left: 6%; padding-right: 6%;}
  }
</style>
<link rel="icon" href="/assets/favicon.png">

   <title>Algunos análisis sobre el estado de los LLMs al finalizar 2025</title>  
</head>
<body>
<div class="sidebar">
  <div class=style="text-align: center;"><img src="/assets/foto perfil cv 2025.jpeg" alt="Foto de perfil" width="210" height="210"></div>
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h2><a href="/">Modelizando sistemas</a></h2>
      <p class="lead">Un blog personal-profesional de Enrique Gabriel Baquela</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item " href="/">Inicio</a>
      <a class="sidebar-nav-item " href="/sobre_mi/">Sobre mi</a>
      <a class="sidebar-nav-item " href="/en_los_medios/">Apariciones en los medios</a>
      <a class="sidebar-nav-item " href="/lista_posts/">Posts</a>
    </nav>
    <p>&copy; Enrique Gabriel Baquela.</p>
  </div>
</div>
<div class="content container">

<!-- Content appended here -->
<div class="franklin-content">
<h1 id="algunos_análisis_sobre_el_estado_de_los_llms_al_finalizar_2025"><a href="#algunos_análisis_sobre_el_estado_de_los_llms_al_finalizar_2025" class="header-anchor">Algunos análisis sobre el estado de los LLMs al finalizar 2025</a></h1>
<p>Mucho se habló en este año sobre los LLM, derivados y similares, pero acá tengo dos buenos resúmenes:</p>
<ul>
<li><p>Resumen por Andrej Karpathy: <a href="https://karpathy.bearblog.dev/year-in-review-2025/">https://karpathy.bearblog.dev/year-in-review-2025/</a></p>
</li>
<li><p>Un análisis de Peter Novig: <a href="https://github.com/norvig/pytudes/blob/main/ipynb/Advent-2025-AI.ipynb">https://github.com/norvig/pytudes/blob/main/ipynb/Advent-2025-AI.ipynb</a></p>
</li>
</ul>
<p>La siguiente lectura también es interesante, aunque no totalmente imparcial, acerca de por que necesitamos construir memoria en los agentes de IA: <a href="https://www.linkedin.com/pulse/decision-traces-agentic-operations-why-agents-need-van-schalkwyk-vhqmc/">https://www.linkedin.com/pulse/decision-traces-agentic-operations-why-agents-need-van-schalkwyk-vhqmc/</a>.</p>
<p>Pero, ya que es muy posible que escalar las redes neuronales y los datos no sea el camino a la AGI, sino que se necesite enfoques que combinen los desarrollos actuales con IA simbólica, siempre es bueno escuchar a <a href="https://garymarcus.substack.com/">Gary Marcus</a>: <a href="https://garymarcus.substack.com/p/a-case-for-ai-models-that-understand">https://garymarcus.substack.com/p/a-case-for-ai-models-that-understand</a>. En la misma línea, un análisis crítico sobre la el uso de LLM en análisis de datos: <a href="https://journals.sagepub.com/doi/epub/10.1177/10944281251377154">https://journals.sagepub.com/doi/epub/10.1177/10944281251377154</a></p>
<div class="page-foot">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> Enrique Gabriel Baquela. Last modified: December 27, 2025.
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
</div>
</div><!-- CONTENT ENDS HERE -->
    </div>  <!-- div: content container -->
    
    
  </body>
</html>
